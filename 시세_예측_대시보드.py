# ì‹œì„¸_ì˜ˆì¸¡_ëŒ€ì‹œë³´ë“œ.py

import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import altair as alt
import os
import shutil

from data_loader import load_merged_data, load_gpt_scores
from features import filter_item, make_ml_dataset
from models.io import load_or_train_model
from backtest import simulate_strict_investor
from preprocess import apply_gpt_scores, clean_outliers_rolling, resample_to_30min_for_app


# -------------------------------------------------------------------------
# 1. ì‹œê°„ í•´ìƒë„ / ì˜ˆì¸¡ êµ¬ê°„ ì„¤ì • (30ë¶„ ë‹¨ìœ„ ê¸°ì¤€)
# -------------------------------------------------------------------------
TIME_STEP_MINUTES = 30
POINTS_PER_DAY = int(24 * 60 / TIME_STEP_MINUTES)  # 48
FORECAST_DAYS = 3
FORECAST_STEPS = FORECAST_DAYS * POINTS_PER_DAY    # 144


# -------------------------------------------------------------------------
# 2. í˜ì´ì§€ ì„¤ì • & ì„¸ì…˜ ì´ˆê¸°í™”
# -------------------------------------------------------------------------
st.set_page_config(
	page_title="ë””ì§€í„¸ ìì‚° ì‹œì„¸ ë³€ë™ ì˜ˆì¸¡ ëª¨ë¸",
	layout="wide"
)

if "rf_result" not in st.session_state:
	st.session_state.rf_result = None

st.title("ë””ì§€í„¸ ìì‚° ì‹œì„¸ ë³€ë™ ì˜ˆì¸¡ ëª¨ë¸")
st.caption("ë¡œìŠ¤íŠ¸ì•„í¬ ê±°ë˜ì†Œ ì•„ì´í…œ ì‹œì„¸ë¥¼ ì•™ìƒë¸” ëª¨ë¸(LightGBM / XGBoost / NeuralProphet)ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")


# -------------------------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” - ê²€ìƒ‰ / í•™ìŠµ ë²”ìœ„ ì„¤ì • + ê²€ì¦ ëª¨ë¸ ì„ íƒ
# -------------------------------------------------------------------------
with st.sidebar:
	st.header("ì•„ì´í…œ ê²€ìƒ‰")

	# 1) ë°ì´í„° ë¡œë”©
	df_final = load_merged_data()
	df_gpt_all = load_gpt_scores()

	grade_list = sorted(df_final["grade"].dropna().unique())
	grade_options = ["ì „ì²´"] + grade_list

	# 2) ë“±ê¸‰ ì„ íƒ
	target_grade = st.selectbox(
		"ì•„ì´í…œ ë“±ê¸‰",
		grade_options,
		index=grade_options.index("ìœ ë¬¼") if "ìœ ë¬¼" in grade_options else 0,
	)

	# 3) ë“±ê¸‰ì— ë”°ë¼ ì•„ì´í…œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ë™ì  ìƒì„±
	if target_grade == "ì „ì²´":
		item_options = sorted(df_final["name"].dropna().unique())
	else:
		item_options = sorted(
			df_final.loc[df_final["grade"] == target_grade, "name"]
			.dropna()
			.unique()
		)

	if len(item_options) == 0:
		st.warning("ì„ íƒí•œ ë“±ê¸‰ì— í•´ë‹¹í•˜ëŠ” ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤.")
		st.stop()

	default_item_name = "ìœ ë¬¼ ì›í•œ ê°ì¸ì„œ"

	default_index = 0
	if default_item_name in item_options:
		default_index = item_options.index(default_item_name)


	# 4) ì•„ì´í…œ ì´ë¦„ ì„ íƒ (íƒ€ì´í•‘í•˜ë©´ ìë™ í•„í„°ë§ë¨)
	target_item_name = st.selectbox(
		"ì•„ì´í…œ ì´ë¦„",
		item_options,
		index=default_index,
		help="ì•„ì´í…œ ì´ë¦„ì˜ ì¼ë¶€ë¥¼ íƒ€ì´í•‘í•˜ë©´ ìë™ìœ¼ë¡œ í•„í„°ë§ë©ë‹ˆë‹¤.",
	)


	# filter_item() ì—ì„œ ì“°ë˜ ë³€ìˆ˜ëª… ìœ ì§€
	target_keyword = target_item_name

	# 5) ê·¸ë˜í”„ í‘œì‹œ ê¸°ê°„
	days_to_show = st.slider(
		"ê·¸ë˜í”„ í‘œì‹œ ê¸°ê°„ (ì¼)",
		min_value=1,
		max_value=14,
		value=3,
		step=1,
	)
	zoom_n = days_to_show * POINTS_PER_DAY

	# ğŸ”¹ Yì¶• ë²”ìœ„ë¥¼ ì „ì²´ ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œ ê³ ì •í• ì§€ ì—¬ë¶€
	use_global_scale = st.checkbox(
		"Yì¶• ë²”ìœ„ë¥¼ ì „ì²´ ê¸°ê°„ìœ¼ë¡œ ê³ ì •",
		value=False,
	)	

	# 6) ì‹¤í–‰ ë²„íŠ¼ (í¼ ëŒ€ì‹  ì¼ë°˜ ë²„íŠ¼)
	# run_button = st.button("í•™ìŠµ & ì˜ˆì¸¡ ì‹¤í–‰")
	run_button = st.button("AI ì˜ˆì¸¡ ì‹œì‘", type="primary", use_container_width=True)

	zoom_n = days_to_show * POINTS_PER_DAY

	# 3-3. ê²€ì¦ìš© ë‹¨ì¼ ëª¨ë¸ ì„ íƒ (ì˜ˆì¸¡ì€ í•­ìƒ ì•™ìƒë¸” ëª¨ë¸)
	st.markdown("---")
	st.subheader("ğŸ” ê²€ì¦ ëª¨ë¸ ì„ íƒ")

	eval_model_key = st.selectbox(
		"ê²€ì¦ì— ì‚¬ìš©í•  ë‹¨ì¼ ëª¨ë¸",
		["lgbm", "xgb", "rf", "lstm", "np"],
		format_func=lambda k: {
			"lgbm": "LightGBM",
			"xgb": "XGBoost",
			"rf": "RandomForest",
			"lstm": "LSTM",
			"np": "NeuralProphet",
		}[k],
	)

	# ğŸ”¹ ê´€ë¦¬ì ì„¤ì • ì˜ì—­ ì¶”ê°€
	st.markdown("---")
	with st.expander("âš™ï¸ ê´€ë¦¬ì ì„¤ì •"):
		st.caption("ì €ì¥ëœ ëª¨ë¸ í•™ìŠµ ê²°ê³¼(.pkl)ì™€ ì˜ˆì¸¡ ìºì‹œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")

		if st.button("ëª¨ë¸ ì´ˆê¸°í™”", type="secondary", use_container_width=True):
			model_dir = "trained_models"  # ğŸ”¥ ë°˜ë“œì‹œ ì—¬ê¸°

			try:
				# 1) í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ë§Œ ì‚­ì œ
				if os.path.exists(model_dir):
					shutil.rmtree(model_dir)

				# 2) ë¹ˆ í´ë” ì¬ìƒì„±
				os.makedirs(model_dir, exist_ok=True)

				# 3) ì„¸ì…˜ ìºì‹œ ì´ˆê¸°í™”
				st.session_state.rf_result = None

				st.success(
					"í•™ìŠµëœ ëª¨ë¸(.pkl)ê³¼ ì„¸ì…˜ ìºì‹œë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.\n"
					"ë‹¤ì‹œ [í•™ìŠµ & ì˜ˆì¸¡ ì‹¤í–‰]ì„ ëˆŒëŸ¬ ëª¨ë¸ì„ ì¬í•™ìŠµí•´ì£¼ì„¸ìš”."
				)
			except Exception as e:
				st.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# -------------------------------------------------------------------------
# 4. ë²„íŠ¼ ëˆŒë €ì„ ë•Œë§Œ ìƒˆë¡œ ê³„ì‚° â†’ ì „ì²˜ë¦¬ + Feature Engineering
# -------------------------------------------------------------------------
if run_button:
	with st.spinner("ë°ì´í„° í•„í„°ë§ ì¤‘..."):
		result = filter_item(df_final, target_keyword, target_grade)

	if result is None:
		st.error(f"'{target_keyword}' (ë“±ê¸‰: {target_grade}) ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
	else:
		# ğŸ”¹ UIìš© ì›ë³¸ (10ë¶„ ë‹¨ìœ„)
		df_target, top_item = result

		# 4-1. 30ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜ (ML ì „ìš©)
		df_target_30 = resample_to_30min_for_app(df_target)

		# 4-2. item_id ì¶”ì¶œ
		item_id = None
		if "item_id" in df_target.columns:
			try:
				item_id = int(df_target["item_id"].iloc[0])
			except Exception:
				item_id = None

		# 4-3. í•´ë‹¹ ì•„ì´í…œì— ëŒ€í•œ GPT ì ìˆ˜ë§Œ í•„í„°ë§
		if item_id is not None:
			df_gpt_item = df_gpt_all[df_gpt_all["item_id"] == item_id].copy()
		else:
			df_gpt_item = None

		# 4-4. GPT ì ìˆ˜ ë§¤í•‘ (date index ê¸°ì¤€)
		df_target_for_ml = (
			df_target_30
			.sort_values("date")
			.set_index("date")
		)

		df_target_with_gpt = apply_gpt_scores(
			df_target_for_ml,
			df_gpt_item,
			score_col="gpt_score",
		)

		# 4-5. ì´ìƒì¹˜ ì •ì œ (30ë¶„ ê¸°ì¤€)
		df_target_clean = clean_outliers_rolling(
			df_target_with_gpt,
			column="price",
			window=POINTS_PER_DAY,   # í•˜ë£¨ ê¸°ì¤€
			sigma=3.0,
		)

		df_target_clean = df_target_clean.reset_index()

		# 4-6. Feature Engineering
		with st.spinner("Feature Engineering ì²˜ë¦¬ ì¤‘..."):
			df_ml, features = make_ml_dataset(df_target_clean)

		if len(df_ml) < 300:
			st.warning(
				f"Feature ìƒì„± í›„ ë°ì´í„°ê°€ {len(df_ml)}ê°œì…ë‹ˆë‹¤. "
				"(ìµœì†Œ 300ê°œ ì´ìƒì¼ ë•Œê°€ ë” ì•ˆì •ì )"
			)
		else:
			# -----------------------------------------------------------------
			# 5. ì•™ìƒë¸” ëª¨ë¸ (LightGBM / XGBoost / NeuralProphet)
			#    - í•­ìƒ í•™ìŠµ/ë¡œë“œ í›„ ë¯¸ë˜ ì˜ˆì¸¡
			#    - ì˜ˆì¸¡ê°’ì€ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ merge í›„ ê°€ì¤‘ í‰ê· 
			# -----------------------------------------------------------------
			with st.spinner("ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ / ë¡œë“œ ì¤‘..."):
				ensemble_keys = ["lgbm", "xgb", "np"]
				ensemble_weights = {
					"lgbm": 4.0,
					"xgb": 4.5,
					"np": 1.5,
				}

				ensemble_models: dict[str, object] = {}
				ensemble_status: dict[str, str] = {}
				ensemble_future: dict[str, pd.DataFrame | None] = {}

				for key in ensemble_keys:
					m, status = load_or_train_model(
						model_key=key,
						item_id=item_id,
						df_ml=df_ml,
						features=features,
					)
					ensemble_models[key] = m
					ensemble_status[key] = status

					try:
						fut = m.predict_future(steps=FORECAST_STEPS)
					except NotImplementedError:
						fut = None

					ensemble_future[key] = fut

				# 5-2. ì•™ìƒë¸” ëª¨ë¸ ë¯¸ë˜ ì˜ˆì¸¡ (ë‚ ì§œ ê¸°ì¤€ merge + ê°€ì¤‘ í‰ê· )
				valid_keys = [
					k for k in ensemble_keys
					if ensemble_future.get(k) is not None
					and not ensemble_future[k].empty
				]

				if len(valid_keys) == 0:
					ensemble_future_df = None
				else:
					df_ens = None
					for k in valid_keys:
						df_k = ensemble_future[k][["date", "price"]].copy()
						df_k = df_k.rename(columns={"price": f"price_{k}"})
						if df_ens is None:
							df_ens = df_k
						else:
							df_ens = pd.merge(df_ens, df_k, on="date", how="inner")

					# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë§Œìœ¼ë¡œ ê°€ì¤‘ í‰ê·  ê³„ì‚°
					total_w = sum(ensemble_weights[k] for k in valid_keys)
					weighted_sum = 0.0
					for k in valid_keys:
						w = ensemble_weights[k]
						weighted_sum += df_ens[f"price_{k}"] * w

					df_ens["ensemble_price"] = weighted_sum / total_w
					ensemble_future_df = df_ens  # date + price_lgbm/xgb/np + ensemble_price

			# -----------------------------------------------------------------
			# 6. ê²€ì¦ìš© ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ / í‰ê°€
			#    - eval_model_key ê¸°ì¤€
			#    - lgbm/xgbëŠ” ì´ë¯¸ ensembleì—ì„œ í•™ìŠµëœ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
			# -----------------------------------------------------------------
			with st.spinner("ì„ íƒí•œ ê²€ì¦ ëª¨ë¸ í•™ìŠµ / í‰ê°€ ì¤‘..."):
				if eval_model_key in ensemble_models:
					eval_model = ensemble_models[eval_model_key]
					eval_status = ensemble_status[eval_model_key]
				else:
					eval_model, eval_status = load_or_train_model(
						model_key=eval_model_key,
						item_id=item_id,
						df_ml=df_ml,
						features=features,
					)

				eval_model_name = {
					"lgbm": "LightGBM",
					"xgb": "XGBoost",
					"rf": "RandomForest",
					"lstm": "LSTM",
					"np": "NeuralProphet",
				}[eval_model_key]

				if eval_status == "loaded":
					st.info(f"ğŸ“¦ ê²€ì¦ ëª¨ë¸({eval_model_name})ì„ ì €ì¥ëœ ìƒíƒœì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
				else:
					st.success(f"ğŸ§  ê²€ì¦ ëª¨ë¸({eval_model_name})ì„ ìƒˆë¡œ í•™ìŠµí•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

				y_test, y_pred, split_idx, rmse, r2 = eval_model.predict_test()

			# -----------------------------------------------------------------
			# 7. ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥ (ì•™ìƒë¸” ëª¨ë¸ + ê²€ì¦ ëª¨ë¸)
			# -----------------------------------------------------------------
			st.session_state.rf_result = {
				"df_target": df_target,          # UIìš© (10ë¶„)
				"df_ml": df_ml,                  # MLìš© (30ë¶„, gpt_score í¬í•¨)
				"top_item": top_item,
				"y_test": y_test,
				"y_pred": y_pred,
				"split_idx": split_idx,
				"rmse": rmse,
				"r2": r2,
				# "days_to_show": days_to_show,
				"future_df_ensemble": ensemble_future_df,  # ğŸ”¥ ì•™ìƒë¸” ëª¨ë¸ ì˜ˆì¸¡ + ê°œë³„
				"eval_model_key": eval_model_key,
				"eval_model_name": eval_model_name,
				"features": features,
				# "use_global_scale": use_global_scale,
			}


# -------------------------------------------------------------------------
# 8. ì„¸ì…˜ì— ê²°ê³¼ ì—†ìœ¼ë©´ ì•ˆë‚´ í›„ ì¢…ë£Œ
# -------------------------------------------------------------------------
if st.session_state.rf_result is None:
	st.info("ì•„ì´í…œ ë“±ê¸‰, ì´ë¦„ ì„¤ì • í›„ **[AI ì˜ˆì¸¡ ì‹œì‘]** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
	st.stop()


# -------------------------------------------------------------------------
# 9. ì„¸ì…˜ì—ì„œ ê²°ê³¼ êº¼ë‚´ì„œ ê³µí†µ ë³€ìˆ˜ ì¤€ë¹„
# -------------------------------------------------------------------------
res = st.session_state.rf_result

df_target = res["df_target"]
df_ml = res["df_ml"]
top_item = res["top_item"]
y_test = res["y_test"]
y_pred = res["y_pred"]
split_idx = res["split_idx"]
rmse = res["rmse"]
r2 = res["r2"]
# days_to_show = res["days_to_show"]
future_df_ensemble = res["future_df_ensemble"]
eval_model_key = res["eval_model_key"]
eval_model_name = res["eval_model_name"]
# use_global_scale = res.get("use_global_scale", False)
zoom_n = days_to_show * POINTS_PER_DAY


st.subheader(f"ğŸ¯ ë¶„ì„ ëŒ€ìƒ: {top_item}")


# -------------------------------------------------------------------------
# 10. í˜„ì¬ ê°€ê²© & ì „ì¼ í‰ê·  ê°€ê²©
# -------------------------------------------------------------------------
latest_ts = df_target["date"].max()
latest_row = df_target.loc[df_target["date"] == latest_ts].iloc[-1]
current_price = float(latest_row["price"])

current_day_start = latest_ts.normalize()  # ë‹¹ì¼ 00:00
prev_day_start = current_day_start - pd.Timedelta(days=1)
prev_day_end = current_day_start          # ì „ë‚  23:59:59ê¹Œì§€

mask_prev = (df_target["date"] >= prev_day_start) & (df_target["date"] < prev_day_end)
df_prev = df_target.loc[mask_prev]

if not df_prev.empty:
	yesterday_avg_price = float(df_prev["price"].mean())
	yesterday_text = f"{yesterday_avg_price:,.0f} G"
else:
	yesterday_avg_price = None
	yesterday_text = "ë°ì´í„° ì—†ìŒ"

price_col1, price_col2 = st.columns(2)
with price_col1:
	st.metric("í˜„ì¬ ê°€ê²©", f"{current_price:,.0f} G")
with price_col2:
	st.metric("ì „ì¼ í‰ê·  ê°€ê²©", yesterday_text)


# -------------------------------------------------------------------------
# 11. ì•™ìƒë¸” ëª¨ë¸ ê¸°ë°˜ ë©”ì¸ ì˜ˆì¸¡ ê·¸ë˜í”„ (íˆìŠ¤í† ë¦¬ + ë¯¸ë˜)
# -------------------------------------------------------------------------
st.markdown("### ğŸ”® ì•™ìƒë¸” ëª¨ë¸ ê¸°ë°˜ í–¥í›„ 3ì¼ ì‹œì„¸ ì˜ˆì¸¡")

st.caption(
	"ì•™ìƒë¸” ëª¨ë¸ (LightGBM 5.5 : XGBoost 3.5 : NeuralProphet 1.0 ê°€ì¤‘ í‰ê· )\n"
	"ì ì„ ì€ ê° ê°œë³„ ëª¨ë¸ì˜ ì˜ˆì¸¡, ì‹¤ì„ ì€ ì•™ìƒë¸” ëª¨ë¸ê³¼ ì‹¤ì œ íˆìŠ¤í† ë¦¬ì…ë‹ˆë‹¤."
)

if future_df_ensemble is None or future_df_ensemble.empty:
	st.info("ì•™ìƒë¸” ëª¨ë¸ ì˜ˆì¸¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (í•„ìš” ëª¨ë¸ì˜ predict_future ë¯¸êµ¬í˜„ ë˜ëŠ” ë°ì´í„° ë¶€ì¡±)")
else:
	if zoom_n > len(df_ml):
		zoom_n = len(df_ml)

	# 11-1. ìµœê·¼ íˆìŠ¤í† ë¦¬ êµ¬ê°„
	hist_tail = df_ml[["date", "price"]].iloc[-zoom_n:].copy()
	hist_tail["type"] = "History"

	# 11-2. ë¯¸ë˜ ì˜ˆì¸¡: ì•™ìƒë¸” + ê°œë³„ 3ê°œ
	df_ens_raw = future_df_ensemble.copy()

	# ì•™ìƒë¸” ë©”ì¸ ë¼ì¸
	main_future = pd.DataFrame({
		"date": df_ens_raw["date"],
		"price": df_ens_raw["ensemble_price"],
		"type": "Ensemble Forecast",
	})

	# ê°œë³„ ëª¨ë¸ë“¤ (ì ì„  + íˆ¬ëª…)
	indiv_frames = []

	if "price_lgbm" in df_ens_raw.columns:
		indiv_frames.append(pd.DataFrame({
			"date": df_ens_raw["date"],
			"price": df_ens_raw["price_lgbm"],
			"type": "LightGBM",
		}))

	if "price_xgb" in df_ens_raw.columns:
		indiv_frames.append(pd.DataFrame({
			"date": df_ens_raw["date"],
			"price": df_ens_raw["price_xgb"],
			"type": "XGBoost",
		}))

	if "price_np" in df_ens_raw.columns:
		indiv_frames.append(pd.DataFrame({
			"date": df_ens_raw["date"],
			"price": df_ens_raw["price_np"],
			"type": "NeuralProphet",
		}))

	if len(indiv_frames) > 0:
		df_indiv = pd.concat(indiv_frames, ignore_index=True)
	else:
		df_indiv = pd.DataFrame(columns=["date", "price", "type"])

	# ğŸ”¹ ìˆ˜ìš”ì¼ 06:00 ì„¸ë¡œì„ ìš© ë°ì´í„° ìƒì„±
	# "ìµœê·¼ zoom_n íˆìŠ¤í† ë¦¬ êµ¬ê°„ + ë¯¸ë˜ ì˜ˆì¸¡" ë²”ìœ„ì— ëŒ€í•´ì„œë§Œ ìƒì„±
	date_start = hist_tail["date"].min()          # âœ… ìµœê·¼ êµ¬ê°„ ì‹œì‘ ì‹œì 
	date_end = df_ens_raw["date"].max()           # âœ… ì˜ˆì¸¡ ë§ˆì§€ë§‰ ì‹œì 

	wednesday_6am = (
		pd.date_range(
			start=date_start.normalize(),
			end=date_end.normalize(),
			freq="W-WED",
		)
		+ pd.Timedelta(hours=6)
	)

	df_wed = pd.DataFrame({"date": wednesday_6am})

	# 11-3. yì¶• ë²”ìœ„ ê³„ì‚° (íˆìŠ¤í† ë¦¬ + ì•™ìƒë¸” + ê°œë³„ ëª¨ë‘ í¬í•¨)
	df_main = pd.concat([hist_tail, main_future], ignore_index=True)

	if use_global_scale:
		# ğŸ”¹ ì „ì²´ ê¸°ê°„ ê°€ê²© + ë¯¸ë˜ ì˜ˆì¸¡ê¹Œì§€ í¬í•¨í•´ì„œ Yì¶• ë²”ìœ„ ê³„ì‚°
		df_all_hist = df_ml[["date", "price"]].copy()
		df_all_hist["type"] = "History (ì „ì²´)"

		df_for_range = pd.concat(
			[df_all_hist, main_future, df_indiv],
			ignore_index=True
		)
	else:
		# ê¸°ì¡´ì²˜ëŸ¼: ìµœê·¼ êµ¬ê°„(hist_tail) + ì•™ìƒë¸” + ê°œë³„ ëª¨ë¸ ê¸°ì¤€
		df_for_range = pd.concat([df_main, df_indiv], ignore_index=True)

	y_min_f = df_for_range["price"].min()
	y_max_f = df_for_range["price"].max()
	padding_f = (y_max_f - y_min_f) * 0.05
	y_domain_f = [y_min_f - padding_f, y_max_f + padding_f]

	# 11-4. Altair ë ˆì´ì–´ êµ¬ì„± (íˆìŠ¤í† ë¦¬ + ì•™ìƒë¸” + ê°œë³„ + ìˆ˜ìš”ì¼ 06:00 ì ì„ )
	base_chart = (
		alt.Chart(df_main)
		.mark_line()
		.encode(
			x=alt.X("date:T", title="ì‹œê°„"),
			y=alt.Y(
				"price:Q",
				title="ê°€ê²© (Gold)",
				scale=alt.Scale(domain=y_domain_f)
			),
			color=alt.Color("type:N", title="êµ¬ë¶„"),
			tooltip=[
				alt.Tooltip("date:T", title="ì‹œê°„"),
				alt.Tooltip("type:N", title="êµ¬ë¶„"),
				alt.Tooltip("price:Q", title="ê°€ê²©"),
			],
		)
	)

	indiv_chart = (
		alt.Chart(df_indiv)
		.mark_line(strokeDash=[4, 4], opacity=0.35)  # ì ì„  + ë°˜íˆ¬ëª…
		.encode(
			x=alt.X("date:T", title="ì‹œê°„"),
			y=alt.Y(
				"price:Q",
				title="ê°€ê²© (Gold)",
				scale=alt.Scale(domain=y_domain_f)
			),
			color=alt.Color("type:N", title="ëª¨ë¸"),
			tooltip=[
				alt.Tooltip("date:T", title="ì‹œê°„"),
				alt.Tooltip("type:N", title="ëª¨ë¸"),
				alt.Tooltip("price:Q", title="ê°€ê²©"),
			],
		)
	)

	# ğŸ”¹ ìˆ˜ìš”ì¼ 06:00 ì„¸ë¡œ ì ì„  ë ˆì´ì–´
	wed_rule = (
		alt.Chart(df_wed)
		.mark_rule(
			color="orange",
			strokeDash=[6, 6],
			opacity=0.6,
		)
		.encode(
			x="date:T"
		)
	)

	chart_future = (
		(base_chart + indiv_chart + wed_rule)
		.properties(
			title=f"[{top_item}] ìµœê·¼ {days_to_show}ì¼ + ì•™ìƒë¸” ëª¨ë¸ ê¸°ë°˜ í–¥í›„ {FORECAST_DAYS}ì¼ ì‹œì„¸ ì˜ˆì¸¡",
		)
		.interactive()
	)

	st.altair_chart(chart_future, use_container_width=True)



# -------------------------------------------------------------------------
# 12. ê²€ì¦ ê²°ê³¼ (RMSE / RÂ² + ìµœê·¼ í…ŒìŠ¤íŠ¸ êµ¬ê°„ ê·¸ë˜í”„) - expander
# -------------------------------------------------------------------------
with st.expander("ğŸ“Š ê²€ì¦ ëª¨ë¸ ì„±ëŠ¥ ë° ìµœê·¼ í…ŒìŠ¤íŠ¸ êµ¬ê°„ ë³´ê¸°", expanded=False):
	st.markdown(f"#### ê²€ì¦ ëª¨ë¸: {eval_model_name}")

	col1, col2 = st.columns(2)
	with col1:
		st.metric("RMSE (ê³¨ë“œ)", f"{rmse:,.2f}")
	with col2:
		st.metric("RÂ²", f"{r2:.3f}")

	st.markdown("##### ğŸ“ˆ ìµœê·¼ í…ŒìŠ¤íŠ¸ êµ¬ê°„ í™•ëŒ€ ê·¸ë˜í”„ (ì¸í„°ë™í‹°ë¸Œ)")

	test_len = len(y_test)

	test_dates = (
		df_ml["date"]
		.iloc[-test_len:]
		.reset_index(drop=True)
		.to_numpy()
	)

	actual = (
		pd.Series(y_test)
		.reset_index(drop=True)
		.to_numpy()
	)

	pred = (
		pd.Series(y_pred)
		.reset_index(drop=True)
		.to_numpy()
	)

	if zoom_n > len(test_dates):
		zoom_n_local = len(test_dates)
	else:
		zoom_n_local = zoom_n

	zoom_slice = slice(-zoom_n_local, None)

	df_plot = pd.DataFrame({
		"date": test_dates[zoom_slice],
		"Actual (ì‹¤ì œ)": actual[zoom_slice],
		"Prediction (ì˜ˆì¸¡)": pred[zoom_slice],
	})

	df_plot_melt = df_plot.melt("date", var_name="type", value_name="price")

	y_min = df_plot_melt["price"].min()
	y_max = df_plot_melt["price"].max()
	padding = (y_max - y_min) * 0.05
	y_domain = [y_min - padding, y_max + padding]

	chart = (
		alt.Chart(df_plot_melt)
		.mark_line()
		.encode(
			x=alt.X("date:T", title="ì‹œê°„"),
			y=alt.Y(
				"price:Q",
				title="ê°€ê²© (Gold)",
				scale=alt.Scale(domain=y_domain)
			),
			color=alt.Color("type:N", title="êµ¬ë¶„"),
			tooltip=[
				alt.Tooltip("date:T", title="ì‹œê°„"),
				alt.Tooltip("type:N", title="êµ¬ë¶„"),
				alt.Tooltip("price:Q", title="ê°€ê²©"),
			],
		)
		.properties(
			title=f"[{top_item}] ê²€ì¦ ëª¨ë¸({eval_model_name}) ê¸°ì¤€ ìµœê·¼ {days_to_show}ì¼ í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì˜ˆì¸¡",
		)
		.interactive()
	)

	st.altair_chart(chart, use_container_width=True)


# -------------------------------------------------------------------------
# 13. ì „ì²´ ì‹œì„¸ & ìˆ˜ìš”ì¼(Reset) í•˜ì´ë¼ì´íŠ¸ - expander
# -------------------------------------------------------------------------
with st.expander("ğŸ“‰ ì „ì²´ ì‹œì„¸ íë¦„ & ìˆ˜ìš”ì¼(Reset) ì˜í–¥ ë¶„ì„", expanded=False):
	st.markdown("#### ì „ì²´ ì‹œì„¸ + ê²€ì¦ êµ¬ê°„ + ì˜ˆì¸¡ êµ¬ê°„ í‘œì‹œ")

	all_dates = df_ml["date"].reset_index(drop=True).to_numpy()
	all_prices = df_ml["price"].reset_index(drop=True).to_numpy()

	df_line_all = pd.DataFrame({
		"date": all_dates,
		"price": all_prices,
		"type": "History (ì „ì²´ íë¦„)",
	})

	test_len = len(y_test)
	test_dates_full = all_dates[-test_len:]
	real_test_price = all_prices[-test_len:]
	pred_price = np.asarray(y_pred)

	df_line_test = pd.DataFrame({
		"date": test_dates_full,
		"price": real_test_price,
		"type": "Actual (ê²€ì¦ êµ¬ê°„)",
	})

	df_line_pred = pd.DataFrame({
		"date": test_dates_full,
		"price": pred_price,
		"type": "Prediction (ê²€ì¦ êµ¬ê°„ ì˜ˆì¸¡)",
	})

	df_lines = pd.concat([df_line_all, df_line_test, df_line_pred], ignore_index=True)

	unique_days = pd.to_datetime(df_ml["date"]).dt.normalize().drop_duplicates()
	weds = unique_days[unique_days.dt.dayofweek == 2]

	df_weds = pd.DataFrame({
		"start": weds,
		"end": weds + pd.Timedelta(days=1),
		"label": "ìˆ˜ìš”ì¼ (Reset)",
	})

	split_idx_all = len(all_dates) - test_len
	split_time = all_dates[split_idx_all]
	df_split = pd.DataFrame({"date": [split_time]})

	y_all_min = all_prices.min()
	y_all_max = all_prices.max()
	padding_all = (y_all_max - y_all_min) * 0.05
	y_domain_all = [y_all_min - padding_all, y_all_max + padding_all]

	rect = (
		alt.Chart(df_weds)
		.mark_rect()
		.encode(
			x="start:T",
			x2="end:T",
			color=alt.value("orange"),
			opacity=alt.value(0.12),
		)
	)

	lines = (
		alt.Chart(df_lines)
		.mark_line()
		.encode(
			x=alt.X("date:T", title="ë‚ ì§œ"),
			y=alt.Y("price:Q", title="ê°€ê²© (Gold)", scale=alt.Scale(domain=y_domain_all)),
			color=alt.Color("type:N", title="êµ¬ë¶„"),
			tooltip=[
				alt.Tooltip("date:T", title="ë‚ ì§œ"),
				alt.Tooltip("type:N", title="êµ¬ë¶„"),
				alt.Tooltip("price:Q", title="ê°€ê²©"),
			],
		)
	)

	rule = (
		alt.Chart(df_split)
		.mark_rule(color="green", strokeDash=[4, 4])
		.encode(
			x="date:T",
			size=alt.value(2),
		)
	)

	chart_all = (
		(rect + lines + rule)
		.properties(
			title=f"[{top_item}] ì „ì²´ ì‹œì„¸ & ìˆ˜ìš”ì¼(Reset) ì˜í–¥ ë¶„ì„ (ê²€ì¦ ëª¨ë¸: {eval_model_name})",
			height=400,
		)
		.interactive()
	)

	st.altair_chart(chart_all, use_container_width=True)


# -------------------------------------------------------------------------
# 14. ì›ì‹œ ë°ì´í„° / Feature ë°ì´í„° í™•ì¸ - expander
# -------------------------------------------------------------------------
with st.expander("ğŸ“‚ ì›ì‹œ ë°ì´í„° / Feature ë°ì´í„° í™•ì¸"):
	st.markdown("#### ğŸ”¹ ì›ë³¸ íƒ€ê²Ÿ ë°ì´í„° (df_target)")
	st.dataframe(df_target[["date", "name", "grade", "price"]].tail(50))

	st.markdown("#### ğŸ”¹ ML í•™ìŠµìš© ë°ì´í„° (df_ml)")
	base_cols = ["date", "price", "lag_30m", "rsi", "is_overbought", "is_oversold"]
	if "gpt_score" in df_ml.columns:
		base_cols.append("gpt_score")

	st.dataframe(df_ml[base_cols].tail(50))


# -------------------------------------------------------------------------
# 15. íˆ¬ì ì‹œë®¬ë ˆì´ì…˜ í˜ì´ì§€ ë§í¬
# -------------------------------------------------------------------------
st.markdown("---")
st.markdown("")
st.markdown("### ğŸ’¼ íˆ¬ì ì‹œë®¬ë ˆì´ì…˜")

st.caption(
	"í˜„ì¬ ë¶„ì„í•œ ì•„ì´í…œê³¼ ë™ì¼í•œ ë°ì´í„°ë¡œ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ë³´ê³  ì‹¶ë‹¤ë©´, "
	"ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ íˆ¬ì ì‹œë®¬ë ˆì´ì…˜ í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”."
)

st.page_link(
	"pages/íˆ¬ì_ì‹œë®¬ë ˆì´ì…˜.py",
	label="íˆ¬ì ì‹œë®¬ë ˆì´ì…˜ í˜ì´ì§€ ì—´ê¸°",
	icon="â¡ï¸",
)
